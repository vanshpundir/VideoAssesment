# -*- coding: utf-8 -*-
"""Confidence_Evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y2stc_n2VV4nMZaQxGCDUbFs7ZpSqG5t
"""

import cv2
from deepface import DeepFace
import time
import os
import matplotlib.pyplot as plt

def get_emotion(video_path):
    def detectemotion(imagefile, enforce_detection=False):
        try:
            img = cv2.imread(imagefile)
            result = DeepFace.analyze(img, actions=['emotion'], enforce_detection=enforce_detection)
            return result
        except Exception as e:
            print(f"Emotion detection failed: {str(e)}")
            return None  # Return None if enforce detection is set to False

    # video_path = r"./vid1.mp4"

    cap = cv2.VideoCapture(video_path)

    results = []  # List to store emotion detection results
    frame_rate = 3  # 1 frame per second
    output_dir = 'frames'  # Directory to store temporary frame images

    # Create the output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)

    while True:
        ret, frame = cap.read()

        if not ret:
            break  # Break the loop when we reach the end of the video

        # Get the current time
        current_time = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0

        # Detect emotion every 1 second
        if current_time >= len(results) * frame_rate:
            # Save the frame as an image file
            frame_filename = os.path.join(output_dir, f"frame_{len(results)}.jpg")
            cv2.imwrite(frame_filename, frame)

            # Detect emotion on the saved frame
            emotion_result = detectemotion(frame_filename)
            results.append(emotion_result)

    # Release the video capture object
    cap.release()

    # Print the emotion results for each second
    final_results = []
    for i, result in enumerate(results):
        dict1 = result[0]['emotion']
        # final_results.append((result[0]['emotion'][list(dict1.keys())[-1]], list((result[0]['emotion']).keys())[-1]))
        final_results.append((list((result[0]['emotion']).keys())[-1]))
        # print(f"Second {i+1}: {result[0]['emotion']}")


    from collections import Counter

    element_counts = Counter(final_results)
    max_count = max(element_counts.values())
    most_common_elements = [element for element, count in element_counts.items() if count == max_count]

    overall_emo = most_common_elements[0]
    score = (max_count / len(final_results)) * 100

    # weights = {"fear": 1,"sad": 2.5, "disgust": 5, "angry": 5, "surprise": 5, "neutral": 8.3, "happy": 10}
    weights = {"fear": -10,"sad": -8, "disgust": -5, "angry": -5, "surprise": 2, "neutral": 8.3, "happy": 10}

    sum = 0
    max_score = 10*len(final_results)

    for emo in final_results:
      sum += weights[emo]

    overall_score = (sum/max_score) * 100

    # print(overall_score)

get_emotion(r'D:\InterviewBot\video_files\64df6ab437474b41bf447f8e.mp4')